services:
  ollama-container:
    image: ollama/ollama
    container_name: ollama_c
    volumes:
      - ./ollama:/root/.ollama
    ports:
      - 11434:11434
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  api:
    build: 
      context: .
      dockerfile: ./api_backend/Dockerfile
    container_name: api_c
    ports:
      - 1702:1702/tcp
    volumes:
      - ./data/clients:/app/data/clients
      - ./huggingface:/root/.cache/huggingface
  
  frontend:
    build: ./frontend
    container_name: frontend_c
    ports:
      - 3000:3000